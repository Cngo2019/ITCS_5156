{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33864c28",
   "metadata": {},
   "source": [
    "## Goal in this notebook:\n",
    "\n",
    "1. Apply machine learning algorithms onto the regular, non-resampled dataset.\n",
    "2. Apply the machine learning algorithms on different features chosen from selectKbest\n",
    "3. Evaluate metrics such as precision, recall, and accuracy\n",
    "4. Repeat for the resampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a65e46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading the files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "X_train = pd.read_csv(\"X_train\", delimiter = \",\")\n",
    "X_test = pd.read_csv(\"X_test\", delimiter = \",\")\n",
    "t_train = pd.read_csv(\"t_train\", delimiter = \",\")\n",
    "t_test = pd.read_csv(\"t_test\",  delimiter = \",\")\n",
    "X_train_rs = pd.read_csv(\"X_train_rs\", delimiter = \",\")\n",
    "t_train_rs = pd.read_csv(\"t_train_rs\", delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8ae226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Selected Features for K = 8\n",
    "k_eight_features = ['patient_nbr', 'time_in_hospital', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses', 'diabetesMed']\n",
    "k_sixteen_features = ['patient_nbr', 'race', 'age', 'admission_source_id', 'time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_3', 'number_diagnoses', 'metformin', 'change', 'diabetesMed']\n",
    "k_thirty_two_features = ['patient_nbr', 'race', 'gender', 'age', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'time_in_hospital', 'medical_specialty', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1', 'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'metformin', 'repaglinide', 'nateglinide', 'glipizide', 'glyburide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'glipizide-metformin', 'glimepiride-pioglitazone', 'change', 'diabetesMed']\n",
    "feature_selection = [k_eight_features, k_sixteen_features, k_thirty_two_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e6a4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea5fc6",
   "metadata": {},
   "source": [
    "## Training and Testing Keeping All Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c3fc9506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readmitted\n",
       "0             49431\n",
       "1             42158\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "30aebfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readmitted\n",
       "0             5433\n",
       "1             4744\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5344e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr\n",
      "Training Score:  0.6158818198691983\n",
      "Testing Score:  0.621008155645082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.77      0.69      5433\n",
      "           1       0.63      0.44      0.52      4744\n",
      "\n",
      "    accuracy                           0.62     10177\n",
      "   macro avg       0.62      0.61      0.60     10177\n",
      "weighted avg       0.62      0.62      0.61     10177\n",
      "\n",
      "AUC  0.6098332546498523\n",
      "dt\n",
      "Training Score:  0.7427092773149614\n",
      "Testing Score:  0.612262945858308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.65      5433\n",
      "           1       0.59      0.55      0.57      4744\n",
      "\n",
      "    accuracy                           0.61     10177\n",
      "   macro avg       0.61      0.61      0.61     10177\n",
      "weighted avg       0.61      0.61      0.61     10177\n",
      "\n",
      "AUC  0.6085127456375674\n",
      "rf\n",
      "Training Score:  0.7700815600126653\n",
      "Testing Score:  0.6469490026530411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.75      0.69      5433\n",
      "           1       0.65      0.53      0.58      4744\n",
      "\n",
      "    accuracy                           0.65     10177\n",
      "   macro avg       0.65      0.64      0.64     10177\n",
      "weighted avg       0.65      0.65      0.64     10177\n",
      "\n",
      "AUC  0.6392350755128626\n",
      "nb\n",
      "Training Score:  0.5827446527421415\n",
      "Testing Score:  0.5893681831581016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.87      0.69      5433\n",
      "           1       0.64      0.27      0.38      4744\n",
      "\n",
      "    accuracy                           0.59     10177\n",
      "   macro avg       0.61      0.57      0.54     10177\n",
      "weighted avg       0.61      0.59      0.55     10177\n",
      "\n",
      "AUC  0.5689853734082114\n",
      "knn\n",
      "Training Score:  0.7804212296236448\n",
      "Testing Score:  0.5765942812223641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.61      0.61      5433\n",
      "           1       0.55      0.53      0.54      4744\n",
      "\n",
      "    accuracy                           0.58     10177\n",
      "   macro avg       0.57      0.57      0.57     10177\n",
      "weighted avg       0.58      0.58      0.58     10177\n",
      "\n",
      "AUC  0.5738894726778984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "dt = DecisionTreeClassifier(max_depth = 15)\n",
    "rf = RandomForestClassifier(n_estimators = 100, max_depth = 15)\n",
    "nb = GaussianNB()\n",
    "models = [lr, dt, rf, nb, knn]\n",
    "name = ['lr', 'dt', 'rf', 'nb', 'knn']\n",
    "\n",
    "k = 0\n",
    "for model in models:\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), (name[0], model)])\n",
    "    pipe.fit(X_train, t_train)\n",
    "    t_pred = pipe.predict(X_test)\n",
    "    print(name[k])\n",
    "    print(\"Training Score: \", pipe.score(X_train, t_train))\n",
    "    print(\"Testing Score: \", pipe.score(X_test, t_test))\n",
    "    print(classification_report(t_test, t_pred))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(t_test, t_pred, pos_label=1)\n",
    "    print(\"AUC \", metrics.auc(fpr, tpr))\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98478833",
   "metadata": {},
   "source": [
    "## Training and Testing Using SelectKBestFeatures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5aab789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 8\n",
      "lr\n",
      "Training Score:  0.6124207055432421\n",
      "Testing Score:  0.6154072909501818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.68      5433\n",
      "           1       0.63      0.43      0.51      4744\n",
      "\n",
      "    accuracy                           0.62     10177\n",
      "   macro avg       0.62      0.60      0.60     10177\n",
      "weighted avg       0.62      0.62      0.60     10177\n",
      "\n",
      "0.6033444863675824\n",
      "dt\n",
      "Training Score:  0.7019511076657677\n",
      "Testing Score:  0.6087255576299498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65      5433\n",
      "           1       0.59      0.54      0.56      4744\n",
      "\n",
      "    accuracy                           0.61     10177\n",
      "   macro avg       0.61      0.60      0.60     10177\n",
      "weighted avg       0.61      0.61      0.61     10177\n",
      "\n",
      "0.6045580859459508\n",
      "rf\n",
      "Training Score:  0.733548788609986\n",
      "Testing Score:  0.6190429399626609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.72      0.67      5433\n",
      "           1       0.61      0.51      0.55      4744\n",
      "\n",
      "    accuracy                           0.62     10177\n",
      "   macro avg       0.62      0.61      0.61     10177\n",
      "weighted avg       0.62      0.62      0.61     10177\n",
      "\n",
      "0.6120292143850165\n",
      "nb\n",
      "Training Score:  0.6019063424647064\n",
      "Testing Score:  0.6015525203891127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.82      0.69      5433\n",
      "           1       0.63      0.35      0.45      4744\n",
      "\n",
      "    accuracy                           0.60     10177\n",
      "   macro avg       0.61      0.59      0.57     10177\n",
      "weighted avg       0.61      0.60      0.58     10177\n",
      "\n",
      "0.5858504869529753\n",
      "knn\n",
      "Training Score:  0.7745580801187916\n",
      "Testing Score:  0.5680455930038322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.60      5433\n",
      "           1       0.54      0.51      0.53      4744\n",
      "\n",
      "    accuracy                           0.57     10177\n",
      "   macro avg       0.57      0.56      0.56     10177\n",
      "weighted avg       0.57      0.57      0.57     10177\n",
      "\n",
      "0.5645863344020009\n",
      "K = 16\n",
      "lr\n",
      "Training Score:  0.6135452947406348\n",
      "Testing Score:  0.6177655497690872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.68      5433\n",
      "           1       0.63      0.44      0.52      4744\n",
      "\n",
      "    accuracy                           0.62     10177\n",
      "   macro avg       0.62      0.61      0.60     10177\n",
      "weighted avg       0.62      0.62      0.61     10177\n",
      "\n",
      "0.6062883465574348\n",
      "dt\n",
      "Training Score:  0.7322822609702039\n",
      "Testing Score:  0.603812518423897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.64      5433\n",
      "           1       0.58      0.55      0.56      4744\n",
      "\n",
      "    accuracy                           0.60     10177\n",
      "   macro avg       0.60      0.60      0.60     10177\n",
      "weighted avg       0.60      0.60      0.60     10177\n",
      "\n",
      "0.600237264838044\n",
      "rf\n",
      "Training Score:  0.7834892836475996\n",
      "Testing Score:  0.6357472732632407\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68      5433\n",
      "           1       0.63      0.53      0.58      4744\n",
      "\n",
      "    accuracy                           0.64     10177\n",
      "   macro avg       0.63      0.63      0.63     10177\n",
      "weighted avg       0.63      0.64      0.63     10177\n",
      "\n",
      "0.6293050106944352\n",
      "nb\n",
      "Training Score:  0.6048433763879942\n",
      "Testing Score:  0.6045003439127444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.80      0.68      5433\n",
      "           1       0.63      0.38      0.47      4744\n",
      "\n",
      "    accuracy                           0.60     10177\n",
      "   macro avg       0.61      0.59      0.58     10177\n",
      "weighted avg       0.61      0.60      0.58     10177\n",
      "\n",
      "0.589948002944966\n",
      "knn\n",
      "Training Score:  0.7760211379095743\n",
      "Testing Score:  0.5747273263240641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61      5433\n",
      "           1       0.55      0.52      0.53      4744\n",
      "\n",
      "    accuracy                           0.57     10177\n",
      "   macro avg       0.57      0.57      0.57     10177\n",
      "weighted avg       0.57      0.57      0.57     10177\n",
      "\n",
      "0.5714458617299999\n",
      "K = 32\n",
      "lr\n",
      "Training Score:  0.6154778412254747\n",
      "Testing Score:  0.6199272870197504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.69      5433\n",
      "           1       0.63      0.44      0.52      4744\n",
      "\n",
      "    accuracy                           0.62     10177\n",
      "   macro avg       0.62      0.61      0.60     10177\n",
      "weighted avg       0.62      0.62      0.61     10177\n",
      "\n",
      "0.6087006276675951\n",
      "dt\n",
      "Training Score:  0.742479992138794\n",
      "Testing Score:  0.6130490321312764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65      5433\n",
      "           1       0.59      0.55      0.57      4744\n",
      "\n",
      "    accuracy                           0.61     10177\n",
      "   macro avg       0.61      0.61      0.61     10177\n",
      "weighted avg       0.61      0.61      0.61     10177\n",
      "\n",
      "0.6089415667293341\n",
      "rf\n",
      "Training Score:  0.780595923091201\n",
      "Testing Score:  0.6494055222560676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.75      0.69      5433\n",
      "           1       0.65      0.54      0.59      4744\n",
      "\n",
      "    accuracy                           0.65     10177\n",
      "   macro avg       0.65      0.64      0.64     10177\n",
      "weighted avg       0.65      0.65      0.65     10177\n",
      "\n",
      "0.642230867576167\n",
      "nb\n",
      "Training Score:  0.5455676991778489\n",
      "Testing Score:  0.5546821263633683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.70      5433\n",
      "           1       0.73      0.07      0.13      4744\n",
      "\n",
      "    accuracy                           0.55     10177\n",
      "   macro avg       0.64      0.52      0.42     10177\n",
      "weighted avg       0.63      0.55      0.44     10177\n",
      "\n",
      "0.5240682409260253\n",
      "knn\n",
      "Training Score:  0.7809125550011464\n",
      "Testing Score:  0.5776751498476957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.61      0.61      5433\n",
      "           1       0.55      0.54      0.54      4744\n",
      "\n",
      "    accuracy                           0.58     10177\n",
      "   macro avg       0.58      0.58      0.58     10177\n",
      "weighted avg       0.58      0.58      0.58     10177\n",
      "\n",
      "0.5750621979726045\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "#svm = SVC(kernel = 'linear')\n",
    "dt = DecisionTreeClassifier(max_depth = 15)\n",
    "rf = RandomForestClassifier(n_estimators = 100, max_depth = 15)\n",
    "nb = GaussianNB()\n",
    "models = [lr, dt, rf, nb, knn]\n",
    "name = ['lr', 'dt', 'rf', 'nb', 'knn']\n",
    "feature_names = ['K = 8', 'K = 16', 'K = 32']\n",
    "i = 0\n",
    "for feature in feature_selection:\n",
    "    print(feature_names[i])\n",
    "    k = 0\n",
    "    i += 1\n",
    "    for model in models:\n",
    "        pipe = Pipeline([('scaler', StandardScaler()), (name[k], model)])\n",
    "        pipe.fit(X_train[feature], t_train)\n",
    "        t_pred = pipe.predict(X_test[feature])\n",
    "        print(name[k])\n",
    "        print(\"Training Score: \", pipe.score(X_train[feature], t_train))\n",
    "        print(\"Testing Score: \", pipe.score(X_test[feature], t_test))\n",
    "        print(classification_report(t_test, t_pred))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(t_test, t_pred, pos_label=1)\n",
    "        print(metrics.auc(fpr, tpr))\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66a7831",
   "metadata": {},
   "source": [
    "### Model Evaluation Using the Resampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7a65078b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- KEEPING ALL FEATURES -------\n",
      "lr\n",
      "Training Score:  0.6150998361352188\n",
      "Testing Score:  0.6107890340964921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65      5433\n",
      "           1       0.59      0.54      0.57      4744\n",
      "\n",
      "    accuracy                           0.61     10177\n",
      "   macro avg       0.61      0.61      0.61     10177\n",
      "weighted avg       0.61      0.61      0.61     10177\n",
      "\n",
      "0.6065174520581705\n",
      "dt\n",
      "Training Score:  0.7382917602314337\n",
      "Testing Score:  0.615702073302545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      5433\n",
      "           1       0.59      0.58      0.59      4744\n",
      "\n",
      "    accuracy                           0.62     10177\n",
      "   macro avg       0.61      0.61      0.61     10177\n",
      "weighted avg       0.62      0.62      0.62     10177\n",
      "\n",
      "0.6136986194540949\n",
      "rf\n",
      "Training Score:  0.7721065727984463\n",
      "Testing Score:  0.6498968261766729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69      5433\n",
      "           1       0.65      0.55      0.59      4744\n",
      "\n",
      "    accuracy                           0.65     10177\n",
      "   macro avg       0.65      0.64      0.64     10177\n",
      "weighted avg       0.65      0.65      0.65     10177\n",
      "\n",
      "0.643345957609003\n",
      "nb\n",
      "Training Score:  0.5691671218466144\n",
      "Testing Score:  0.593495136091186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.85      0.69      5433\n",
      "           1       0.63      0.30      0.41      4744\n",
      "\n",
      "    accuracy                           0.59     10177\n",
      "   macro avg       0.61      0.58      0.55     10177\n",
      "weighted avg       0.61      0.59      0.56     10177\n",
      "\n",
      "0.5751095128173374\n",
      "knn\n",
      "Training Score:  0.8009042908296413\n",
      "Testing Score:  0.5734499361304903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.59      5433\n",
      "           1       0.54      0.56      0.55      4744\n",
      "\n",
      "    accuracy                           0.57     10177\n",
      "   macro avg       0.57      0.57      0.57     10177\n",
      "weighted avg       0.57      0.57      0.57     10177\n",
      "\n",
      "0.5725751714353202\n",
      "K = 8\n",
      "lr\n",
      "Training Score:  0.6088385830753981\n",
      "Testing Score:  0.6113785988012185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.70      0.66      5433\n",
      "           1       0.60      0.52      0.55      4744\n",
      "\n",
      "    accuracy                           0.61     10177\n",
      "   macro avg       0.61      0.61      0.60     10177\n",
      "weighted avg       0.61      0.61      0.61     10177\n",
      "\n",
      "0.6053053074258272\n",
      "dt\n",
      "Training Score:  0.700592745443143\n",
      "Testing Score:  0.6068586027316498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      5433\n",
      "           1       0.58      0.56      0.57      4744\n",
      "\n",
      "    accuracy                           0.61     10177\n",
      "   macro avg       0.60      0.60      0.60     10177\n",
      "weighted avg       0.61      0.61      0.61     10177\n",
      "\n",
      "0.603718407496006\n",
      "rf\n",
      "Training Score:  0.724686937347009\n",
      "Testing Score:  0.6219907634862927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67      5433\n",
      "           1       0.61      0.52      0.56      4744\n",
      "\n",
      "    accuracy                           0.62     10177\n",
      "   macro avg       0.62      0.62      0.61     10177\n",
      "weighted avg       0.62      0.62      0.62     10177\n",
      "\n",
      "0.6153915946487784\n",
      "nb\n",
      "Training Score:  0.5898120612571058\n",
      "Testing Score:  0.6031246929350497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.80      0.68      5433\n",
      "           1       0.62      0.38      0.47      4744\n",
      "\n",
      "    accuracy                           0.60     10177\n",
      "   macro avg       0.61      0.59      0.58     10177\n",
      "weighted avg       0.61      0.60      0.58     10177\n",
      "\n",
      "0.5890204651543919\n",
      "knn\n",
      "Training Score:  0.7857619712326273\n",
      "Testing Score:  0.569519504765648\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60      5433\n",
      "           1       0.54      0.53      0.53      4744\n",
      "\n",
      "    accuracy                           0.57     10177\n",
      "   macro avg       0.57      0.57      0.57     10177\n",
      "weighted avg       0.57      0.57      0.57     10177\n",
      "\n",
      "0.5667019229187443\n",
      "K = 16\n",
      "lr\n",
      "Training Score:  0.6131476199146285\n",
      "Testing Score:  0.6128525105630342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.65      5433\n",
      "           1       0.59      0.53      0.56      4744\n",
      "\n",
      "    accuracy                           0.61     10177\n",
      "   macro avg       0.61      0.61      0.61     10177\n",
      "weighted avg       0.61      0.61      0.61     10177\n",
      "\n",
      "0.6079020756919569\n",
      "dt\n",
      "Training Score:  0.7253848799336449\n",
      "Testing Score:  0.6065638203792866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.64      5433\n",
      "           1       0.58      0.55      0.57      4744\n",
      "\n",
      "    accuracy                           0.61     10177\n",
      "   macro avg       0.60      0.60      0.60     10177\n",
      "weighted avg       0.61      0.61      0.61     10177\n",
      "\n",
      "0.603027967709665\n",
      "rf\n",
      "Training Score:  0.7704173494365884\n",
      "Testing Score:  0.6352559693426354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68      5433\n",
      "           1       0.63      0.54      0.58      4744\n",
      "\n",
      "    accuracy                           0.64     10177\n",
      "   macro avg       0.63      0.63      0.63     10177\n",
      "weighted avg       0.63      0.64      0.63     10177\n",
      "\n",
      "0.629446334451663\n",
      "nb\n",
      "Training Score:  0.5998765956585949\n",
      "Testing Score:  0.6091186007664341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.77      0.68      5433\n",
      "           1       0.62      0.42      0.50      4744\n",
      "\n",
      "    accuracy                           0.61     10177\n",
      "   macro avg       0.61      0.60      0.59     10177\n",
      "weighted avg       0.61      0.61      0.60     10177\n",
      "\n",
      "0.5974144561574714\n",
      "knn\n",
      "Training Score:  0.7930751957273775\n",
      "Testing Score:  0.5744325439717008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60      5433\n",
      "           1       0.54      0.55      0.55      4744\n",
      "\n",
      "    accuracy                           0.57     10177\n",
      "   macro avg       0.57      0.57      0.57     10177\n",
      "weighted avg       0.57      0.57      0.57     10177\n",
      "\n",
      "0.5728138019826996\n",
      "K = 32\n",
      "lr\n",
      "Training Score:  0.6153324836640974\n",
      "Testing Score:  0.6131472929153975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65      5433\n",
      "           1       0.59      0.54      0.57      4744\n",
      "\n",
      "    accuracy                           0.61     10177\n",
      "   macro avg       0.61      0.61      0.61     10177\n",
      "weighted avg       0.61      0.61      0.61     10177\n",
      "\n",
      "0.6087395426239436\n",
      "dt\n",
      "Training Score:  0.7383625660010924\n",
      "Testing Score:  0.6155055517343029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      5433\n",
      "           1       0.59      0.58      0.59      4744\n",
      "\n",
      "    accuracy                           0.62     10177\n",
      "   macro avg       0.61      0.61      0.61     10177\n",
      "weighted avg       0.62      0.62      0.62     10177\n",
      "\n",
      "0.6133942641449465\n",
      "rf\n",
      "Training Score:  0.7771135522243127\n",
      "Testing Score:  0.6489142183354624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69      5433\n",
      "           1       0.64      0.55      0.59      4744\n",
      "\n",
      "    accuracy                           0.65     10177\n",
      "   macro avg       0.65      0.64      0.64     10177\n",
      "weighted avg       0.65      0.65      0.65     10177\n",
      "\n",
      "0.6427330761454343\n",
      "nb\n",
      "Training Score:  0.5065444761384557\n",
      "Testing Score:  0.5543873440110052\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.70      5433\n",
      "           1       0.72      0.07      0.13      4744\n",
      "\n",
      "    accuracy                           0.55     10177\n",
      "   macro avg       0.64      0.52      0.41     10177\n",
      "weighted avg       0.63      0.55      0.43     10177\n",
      "\n",
      "0.5237386859517241\n",
      "knn\n",
      "Training Score:  0.8008840606097388\n",
      "Testing Score:  0.5774786282794536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.59      0.60      5433\n",
      "           1       0.55      0.56      0.55      4744\n",
      "\n",
      "    accuracy                           0.58     10177\n",
      "   macro avg       0.58      0.58      0.58     10177\n",
      "weighted avg       0.58      0.58      0.58     10177\n",
      "\n",
      "0.5766023650361028\n"
     ]
    }
   ],
   "source": [
    "print(\"------- KEEPING ALL FEATURES -------\")\n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "#svm = SVC(kernel = 'linear')\n",
    "dt = DecisionTreeClassifier(max_depth = 15)\n",
    "rf = RandomForestClassifier(n_estimators = 100, max_depth = 15)\n",
    "nb = GaussianNB()\n",
    "models = [lr, dt, rf, nb, knn]\n",
    "name = ['lr', 'dt', 'rf', 'nb', 'knn']\n",
    "\n",
    "k = 0\n",
    "for model in models:\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), (name[k], model)])\n",
    "    pipe.fit(X_train_rs, t_train_rs)\n",
    "    t_pred = pipe.predict(X_test)\n",
    "    print(name[k])\n",
    "    print(\"Training Score: \", pipe.score(X_train_rs, t_train_rs))\n",
    "    print(\"Testing Score: \", pipe.score(X_test, t_test))\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(t_test, t_pred, pos_label=1)\n",
    "    print(classification_report(t_test, t_pred))\n",
    "    print(metrics.auc(fpr, tpr))\n",
    "    k += 1\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "#svm = SVC(kernel = 'linear')\n",
    "dt = DecisionTreeClassifier(max_depth = 15)\n",
    "rf = RandomForestClassifier(n_estimators = 100, max_depth = 15)\n",
    "nb = GaussianNB()\n",
    "models = [lr, dt, rf, nb, knn]\n",
    "name = ['lr', 'dt', 'rf', 'nb', 'knn']\n",
    "feature_names = ['K = 8', 'K = 16', 'K = 32']\n",
    "i = 0\n",
    "for feature in feature_selection:\n",
    "    print(feature_names[i])\n",
    "    k = 0\n",
    "    i += 1\n",
    "    for model in models:\n",
    "        pipe = Pipeline([('scaler', StandardScaler()), (name[k], model)])\n",
    "        pipe.fit(X_train_rs[feature], t_train_rs)\n",
    "        t_pred = pipe.predict(X_test[feature])\n",
    "        print(name[k])\n",
    "        print(\"Training Score: \", pipe.score(X_train_rs[feature], t_train_rs))\n",
    "        print(\"Testing Score: \", pipe.score(X_test[feature], t_test))\n",
    "        print(classification_report(t_test, t_pred))\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(t_test, t_pred, pos_label=1)\n",
    "        print(metrics.auc(fpr, tpr))\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a8b388",
   "metadata": {},
   "source": [
    "### Does oversampling hurt or improve our model?\n",
    "\n",
    "In general, it appears that SMOTE resampling doesn't really make any improvements to our model.\n",
    "\n",
    "Still, the random forest classifier seems to be the best. In the next notebook, I will focus on tuning random forest parameters in order to improve our AUC curve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
